"""CLI for Agent Audit."""

from datetime import datetime
from pathlib import Path
from typing import Optional

import click

from .config import Config
from .database import Database
from .parser import (
    discover_sessions as discover_claude_sessions,
    get_project_name_from_dir,
    parse_session as parse_claude_session,
    is_tmp_directory,
)
from .codex_parser import (
    discover_codex_sessions,
    parse_codex_session,
    get_codex_home,
)
from .toml_renderer import render_session_to_file as render_toml_file
from .toml_renderer import render_session_toml


@click.group()
@click.version_option()
@click.option(
    "--config",
    type=click.Path(path_type=Path),
    default=None,
    help="Path to config file",
)
@click.pass_context
def main(ctx, config: Optional[Path]):
    """Archive Claude Code transcripts for analysis."""
    ctx.ensure_object(dict)
    ctx.obj["config"] = Config.load(config)


@main.command()
@click.option(
    "--projects-dir",
    type=click.Path(exists=True, path_type=Path),
    default=None,
    help="Path to Claude projects directory (overrides config)",
)
@click.option(
    "--archive-dir",
    type=click.Path(path_type=Path),
    default=None,
    help="Path to archive output directory (overrides config)",
)
@click.option(
    "--project",
    type=str,
    default=None,
    help="Only sync sessions for a specific project",
)
@click.option(
    "--force",
    is_flag=True,
    help="Re-archive sessions even if they already exist",
)
@click.option(
    "--include-tmp-directories",
    is_flag=True,
    help="Include sessions from temp directories (excluded by default)",
)
@click.option(
    "--no-toml",
    is_flag=True,
    help="Skip generating TOML transcript files (generated by default)",
)
@click.option(
    "--include-warmup",
    is_flag=True,
    help="Include warmup/sidechain sessions (excluded by default)",
)
@click.option(
    "--source",
    type=click.Choice(["all", "claude-code", "codex"]),
    default="all",
    help="Which agent source to sync (default: all)",
)
@click.pass_context
def sync(
    ctx,
    projects_dir: Optional[Path],
    archive_dir: Optional[Path],
    project: str,
    force: bool,
    include_tmp_directories: bool,
    no_toml: bool,
    include_warmup: bool,
    source: str,
):
    """Sync sessions from Claude Code and Codex to the archive."""
    cfg: Config = ctx.obj["config"]

    if archive_dir:
        cfg.archive_dir = archive_dir
    if projects_dir:
        cfg.projects_dir = projects_dir

    cfg.ensure_dirs()
    db = Database(cfg.db_path)

    with db:
        existing_ids = set(db.get_session_ids()) if not force else set()

        synced = 0
        skipped = 0
        errors = 0
        tmp_skipped = 0
        warmup_skipped = 0

        # Sync Claude Code sessions
        if source in ("all", "claude-code"):
            click.echo("=== Syncing Claude Code sessions ===")
            claude_synced, claude_skipped, claude_errors, claude_tmp, claude_warmup = _sync_claude_sessions(
                db, cfg, existing_ids, project, include_tmp_directories, include_warmup, no_toml
            )
            synced += claude_synced
            skipped += claude_skipped
            errors += claude_errors
            tmp_skipped += claude_tmp
            warmup_skipped += claude_warmup

        # Sync Codex sessions
        if source in ("all", "codex"):
            click.echo("\n=== Syncing Codex sessions ===")
            codex_home = get_codex_home()
            if codex_home.exists():
                codex_synced, codex_skipped, codex_errors, codex_warmup = _sync_codex_sessions(
                    db, cfg, existing_ids, project, include_warmup, no_toml
                )
                synced += codex_synced
                skipped += codex_skipped
                errors += codex_errors
                warmup_skipped += codex_warmup
            else:
                click.echo(f"  Codex home not found: {codex_home}")

        click.echo(f"\nDone: {synced} synced, {skipped} skipped, {errors} errors")
        if tmp_skipped > 0:
            click.echo(f"  (Also skipped {tmp_skipped} sessions from temp directories)")
        if warmup_skipped > 0:
            click.echo(f"  (Also skipped {warmup_skipped} warmup/sidechain sessions)")

        # Show stats
        stats = db.get_stats()
        click.echo("\nArchive stats:")
        click.echo(f"  Sessions: {stats['total_sessions']}")
        click.echo(f"  Messages: {stats['total_messages']}")
        click.echo(f"  Tool calls: {stats['total_tool_calls']}")
        click.echo(f"  Input tokens: {stats['total_input_tokens']:,}")
        click.echo(f"  Output tokens: {stats['total_output_tokens']:,}")


def _sync_claude_sessions(
    db: Database,
    cfg: Config,
    existing_ids: set,
    project: Optional[str],
    include_tmp_directories: bool,
    include_warmup: bool,
    no_toml: bool,
) -> tuple[int, int, int, int, int]:
    """Sync Claude Code sessions. Returns (synced, skipped, errors, tmp_skipped, warmup_skipped)."""
    synced = 0
    skipped = 0
    errors = 0
    tmp_skipped = 0
    warmup_skipped = 0

    for jsonl_file, proj_name in discover_claude_sessions(cfg.projects_dir):
        # Get better project name from directory
        proj_name = get_project_name_from_dir(jsonl_file.parent.name)

        # Skip temp directories unless explicitly included
        if not include_tmp_directories and is_tmp_directory(jsonl_file.parent.name):
            tmp_skipped += 1
            continue

        # Filter by project if specified
        if project and proj_name != project:
            continue

        session_id = jsonl_file.stem
        if session_id.startswith("agent-"):
            session_id = session_id[6:]

        if session_id in existing_ids:
            skipped += 1
            continue

        try:
            click.echo(f"  Parsing {jsonl_file.name}...", nl=False)
            session = parse_claude_session(jsonl_file, proj_name)

            # Skip sessions with no messages
            if not session.messages:
                click.echo(" (empty, skipping)")
                skipped += 1
                continue

            # Skip warmup/sidechain sessions unless explicitly included
            if not include_warmup and (session.is_warmup or session.is_sidechain):
                click.echo(" (warmup/sidechain, skipping)")
                warmup_skipped += 1
                continue

            # Insert into database
            db.insert_session(session)

            # Render TOML transcript unless --no-toml
            if not no_toml:
                render_toml_file(session, cfg.toml_dir)

            click.echo(" done")
            synced += 1
        except Exception as e:
            click.echo(f" ERROR: {e}")
            errors += 1

    return synced, skipped, errors, tmp_skipped, warmup_skipped


def _sync_codex_sessions(
    db: Database,
    cfg: Config,
    existing_ids: set,
    project: Optional[str],
    include_warmup: bool,
    no_toml: bool,
) -> tuple[int, int, int, int]:
    """Sync Codex sessions. Returns (synced, skipped, errors, warmup_skipped)."""
    synced = 0
    skipped = 0
    errors = 0
    warmup_skipped = 0

    for rollout_file, proj_name in discover_codex_sessions():
        # Filter by project if specified
        if project and proj_name != project:
            continue

        # Extract session ID from filename
        from .codex_parser import get_session_id_from_filename
        session_id = get_session_id_from_filename(rollout_file) or rollout_file.stem

        if session_id in existing_ids:
            skipped += 1
            continue

        try:
            click.echo(f"  Parsing {rollout_file.name}...", nl=False)
            session = parse_codex_session(rollout_file, proj_name)

            # Skip sessions with no messages
            if not session.messages:
                click.echo(" (empty, skipping)")
                skipped += 1
                continue

            # Skip warmup sessions unless explicitly included
            if not include_warmup and session.is_warmup:
                click.echo(" (warmup, skipping)")
                warmup_skipped += 1
                continue

            # Insert into database
            db.insert_session(session)

            # Render TOML transcript unless --no-toml
            if not no_toml:
                render_toml_file(session, cfg.toml_dir)

            click.echo(" done")
            synced += 1
        except Exception as e:
            click.echo(f" ERROR: {e}")
            errors += 1

    return synced, skipped, errors, warmup_skipped


@main.command()
@click.option(
    "--archive-dir",
    type=click.Path(exists=True, path_type=Path),
    default=None,
    help="Path to archive directory (overrides config)",
)
@click.option(
    "--output-dir",
    type=click.Path(path_type=Path),
    default=None,
    help="Output directory for TOML files (default: archive/transcripts)",
)
@click.option(
    "--session",
    "session_id",
    type=str,
    default=None,
    help="Render a specific session by ID (prefix match)",
)
@click.option(
    "--project",
    type=str,
    default=None,
    help="Render all sessions for a specific project",
)
@click.option(
    "--stdout",
    is_flag=True,
    help="Output to stdout instead of files",
)
@click.pass_context
def render(
    ctx,
    archive_dir: Optional[Path],
    output_dir: Optional[Path],
    session_id: str,
    project: str,
    stdout: bool,
):
    """Render sessions as TOML transcripts."""
    cfg: Config = ctx.obj["config"]

    if archive_dir:
        cfg.archive_dir = archive_dir

    if not cfg.db_path.exists():
        click.echo("No archive database found. Run 'sync' first.")
        return

    output = output_dir or cfg.toml_dir

    db = Database(cfg.db_path)
    with db:
        # Get sessions to render
        if session_id:
            # Find session by prefix match
            all_sessions = db.get_all_sessions()
            sessions = [s for s in all_sessions if s["id"].startswith(session_id)]
            if not sessions:
                click.echo(f"No session found matching '{session_id}'")
                return
        elif project:
            sessions = db.get_sessions_by_project(project)
            if not sessions:
                click.echo(f"No sessions found for project '{project}'")
                return
        else:
            sessions = db.get_all_sessions()

        rendered = 0
        for session_dict in sessions:
            # Reconstruct session object from database
            from .models import Message, Session, ToolCall, ToolResult

            messages: list[Message] = []
            for msg in db.get_messages_for_session(session_dict["id"]):
                messages.append(
                    Message(
                        id=msg["id"],
                        session_id=msg["session_id"],
                        type=msg["type"],
                        timestamp=msg["timestamp"],
                        content=msg["content"] or "",
                        parent_uuid=msg["parent_uuid"],
                        model=msg["model"],
                        input_tokens=msg["input_tokens"],
                        output_tokens=msg["output_tokens"],
                        thinking=msg.get("thinking"),
                        stop_reason=msg.get("stop_reason"),
                        is_sidechain=bool(msg.get("is_sidechain", False)),
                        tool_calls=[],
                    )
                )

            tool_calls = []
            for tc in db.get_tool_calls_for_session(session_dict["id"]):
                tool_call = ToolCall(
                    id=tc["id"],
                    message_id=tc["message_id"],
                    session_id=tc["session_id"],
                    tool_name=tc["tool_name"],
                    input_json=tc["input_json"],
                    timestamp=tc["timestamp"],
                )
                tool_calls.append(tool_call)
                # Attach to message
                for message in messages:
                    if message.id == tc["message_id"]:
                        message.tool_calls.append(tool_call)
                        break

            tool_results = []
            for tr in db.get_tool_results_for_session(session_dict["id"]):
                tool_results.append(
                    ToolResult(
                        id=tr["id"],
                        tool_call_id=tr["tool_call_id"],
                        session_id=tr["session_id"],
                        content=tr["content"] or "",
                        is_error=bool(tr["is_error"]),
                        timestamp=tr["timestamp"],
                    )
                )

            session = Session(
                id=session_dict["id"],
                project=session_dict["project"],
                cwd=session_dict["cwd"],
                git_branch=session_dict["git_branch"],
                slug=session_dict.get("slug"),
                summary=session_dict.get("summary"),
                started_at=session_dict["started_at"],
                ended_at=session_dict["ended_at"],
                claude_version=session_dict["claude_version"],
                total_input_tokens=session_dict["total_input_tokens"] or 0,
                total_output_tokens=session_dict["total_output_tokens"] or 0,
                total_cache_read_tokens=session_dict["total_cache_read_tokens"] or 0,
                model=session_dict["model"],
                parent_session_id=session_dict.get("parent_session_id"),
                is_warmup=bool(session_dict.get("is_warmup", False)),
                is_sidechain=bool(session_dict.get("is_sidechain", False)),
                repo=session_dict.get("repo"),
                repo_platform=session_dict.get("repo_platform"),
                messages=messages,
                tool_calls=tool_calls,
                tool_results=tool_results,
            )

            if stdout:
                click.echo(render_session_toml(session))
                if len(sessions) > 1:
                    click.echo("\n---\n")
            else:
                output_path = render_toml_file(session, output)
                click.echo(f"Rendered: {output_path}")

            rendered += 1

        if not stdout:
            click.echo(f"\nRendered {rendered} sessions to {output}")


@main.command()
@click.option(
    "--archive-dir",
    type=click.Path(exists=True, path_type=Path),
    default=None,
    help="Path to archive directory (overrides config)",
)
@click.pass_context
def stats(ctx, archive_dir: Optional[Path]):
    """Show archive statistics."""
    cfg: Config = ctx.obj["config"]

    if archive_dir:
        cfg.archive_dir = archive_dir

    if not cfg.db_path.exists():
        click.echo("No archive database found. Run 'sync' first.")
        return

    db = Database(cfg.db_path)
    with db:
        s = db.get_stats()

        click.echo("Archive Statistics")
        click.echo("=" * 40)
        click.echo(f"Total sessions:    {s['total_sessions']:,}")
        click.echo(f"Total messages:    {s['total_messages']:,}")
        click.echo(f"Total tool calls:  {s['total_tool_calls']:,}")
        click.echo(f"Input tokens:      {s['total_input_tokens']:,}")
        click.echo(f"Output tokens:     {s['total_output_tokens']:,}")
        click.echo()
        click.echo("Projects:")
        for proj in s["projects"]:
            click.echo(f"  - {proj}")


@main.command()
@click.option(
    "--archive-dir",
    type=click.Path(path_type=Path),
    default=None,
    help="Set archive directory",
)
@click.option(
    "--projects-dir",
    type=click.Path(path_type=Path),
    default=None,
    help="Set Claude projects directory",
)
@click.option(
    "--show",
    is_flag=True,
    help="Show current configuration",
)
@click.pass_context
def config(ctx, archive_dir: Optional[Path], projects_dir: Optional[Path], show: bool):
    """Configure archive settings."""
    cfg: Config = ctx.obj["config"]

    if show or (not archive_dir and not projects_dir):
        click.echo("Current configuration:")
        click.echo(f"  Archive dir:  {cfg.archive_dir}")
        click.echo(f"  Projects dir: {cfg.projects_dir}")
        click.echo(f"  Database:     {cfg.db_path}")
        return

    if archive_dir:
        cfg.archive_dir = archive_dir
    if projects_dir:
        cfg.projects_dir = projects_dir

    cfg.save()
    click.echo("Configuration saved.")
    click.echo(f"  Archive dir:  {cfg.archive_dir}")
    click.echo(f"  Projects dir: {cfg.projects_dir}")


@main.command()
@click.option(
    "--archive-dir",
    type=click.Path(exists=True, path_type=Path),
    default=None,
    help="Path to archive directory (overrides config)",
)
@click.option(
    "--synthesize",
    type=click.Path(exists=True, path_type=Path),
    default=None,
    help="Run global synthesis on existing analysis run directory",
)
@click.option(
    "--recommend",
    type=click.Path(exists=True, path_type=Path),
    default=None,
    help="Generate actionable recommendations from a synthesis file",
)
@click.pass_context
def analyze(
    ctx,
    archive_dir: Optional[Path],
    synthesize: Optional[Path],
    recommend: Optional[Path],
):
    """Analyze archived sessions for patterns and insights.

    By default, runs per-project session analysis on all projects in the database.
    Use --synthesize to run global synthesis on existing analysis files.
    Use --recommend to generate actionable outputs from a synthesis file.
    """

    cfg: Config = ctx.obj["config"]

    if archive_dir:
        cfg.archive_dir = archive_dir

    if recommend:
        _run_recommendations(ctx, cfg, recommend)
        return

    if not cfg.db_path.exists():
        click.echo("No archive database found. Run 'sync' first.")
        return

    if synthesize:
        _run_global_synthesis(ctx, cfg, synthesize)
    else:
        _run_session_analysis(ctx, cfg)


def _run_session_analysis(ctx, cfg: Config):
    """Run per-project session analysis."""
    import asyncio
    from .analyzer.session_analyzer import SessionAnalyzer
    from .analyzer.claude_client import AnalyzerClaudeClient

    db = Database(cfg.db_path)

    # Get all projects from database
    with db:
        projects = db.get_stats()["projects"]

    # Create run directory with timestamp
    timestamp = datetime.utcnow().strftime("%Y%m%d-%H%M%S")
    run_dir = cfg.archive_dir / "analysis" / f"run-{timestamp}"
    run_dir.mkdir(parents=True, exist_ok=True)

    click.echo("Starting session analysis...")
    click.echo(f"Output directory: {run_dir}")
    click.echo()

    async def run_analysis():
        async with AnalyzerClaudeClient() as client:
            with db:
                analyzer = SessionAnalyzer(
                    client=client,
                    db=db,
                    toml_dir=cfg.toml_dir,
                )

                for i, project in enumerate(projects, 1):
                    click.echo(f"Analyzing project {i}/{len(projects)}: {project}...")

                    # Check if project has sessions
                    metrics = db.get_project_metrics(project)
                    if metrics["session_count"] == 0:
                        click.echo("  Skipping (no sessions)")
                        continue

                    click.echo(
                        f"  Sessions: {metrics['session_count']}, Turns: {metrics['turn_count']}"
                    )

                    try:
                        result = await analyzer.analyze_project(project)

                        # Write output
                        output_path = run_dir / f"{project}.md"
                        output_path.write_text(result)
                        click.echo(f"  Written: {output_path}")
                    except Exception as e:
                        click.echo(f"  Error: {e}")

    try:
        asyncio.run(run_analysis())
        click.echo()
        click.echo(f"Analysis complete. Output: {run_dir}")
    except ValueError as e:
        if "ANTHROPIC_API_KEY" in str(e):
            click.echo(f"\nError: {e}")
        else:
            raise


def _parse_validation_toml(validation_content: str) -> Optional[dict]:
    """Parse validation report TOML, handling extra sections gracefully."""
    import tomllib

    toml_start = validation_content.find("```toml\n")
    toml_end = validation_content.rfind("\n```")

    if toml_start == -1 or toml_end == -1:
        return None

    toml_content = validation_content[toml_start + 8 : toml_end]

    # Try parsing full content first
    try:
        return tomllib.loads(toml_content)
    except tomllib.TOMLDecodeError:
        pass

    # Try truncating at problematic sections
    for stop_marker in ["\n[coverage_analysis]", "\ncritical_gaps", "\n[summary"]:
        idx = toml_content.find(stop_marker)
        if idx != -1:
            try:
                return tomllib.loads(toml_content[:idx])
            except tomllib.TOMLDecodeError:
                continue

    return None


def _format_validation_issues(data: dict) -> str:
    """Format validation issues for the fix prompt."""
    reviews = data.get("review", [])
    issues_found = [r for r in reviews if r.get("verdict") != "PASS"]

    if not issues_found:
        return ""

    lines = []
    for review in issues_found:
        verdict = review.get("verdict", "?")
        title = review.get("title", "?")
        lines.append(f"### [{verdict}] {title}")
        lines.append("")
        lines.append("**Issues:**")
        for issue in review.get("issues", []):
            lines.append(f"- {issue}")
        if suggested_fix := review.get("suggested_fix"):
            lines.append("")
            lines.append("**Suggested fix:**")
            lines.append(suggested_fix)
        lines.append("")

    return "\n".join(lines)


def _extract_toml_from_synthesis(synthesis_content: str) -> Optional[str]:
    """Extract the TOML block from synthesis markdown."""
    toml_start = synthesis_content.find("```toml\n")
    if toml_start == -1:
        return None

    # Find the end - need to handle embedded ``` in multi-line strings
    # Use triple-quote tracking like the recommendations parser
    block_start = toml_start + 8
    scan_pos = block_start
    in_triple_quote = False

    while scan_pos < len(synthesis_content):
        if synthesis_content[scan_pos : scan_pos + 3] == '"""':
            in_triple_quote = not in_triple_quote
            scan_pos += 3
            continue

        if (
            not in_triple_quote
            and synthesis_content[scan_pos : scan_pos + 4] == "\n```"
        ):
            after_fence = scan_pos + 4
            if (
                after_fence >= len(synthesis_content)
                or not synthesis_content[after_fence].isalpha()
            ):
                return synthesis_content[block_start:scan_pos]

        scan_pos += 1

    return None


def _replace_toml_in_synthesis(synthesis_content: str, new_toml: str) -> str:
    """Replace the TOML block in synthesis with new content."""
    toml_start = synthesis_content.find("```toml\n")
    if toml_start == -1:
        return synthesis_content

    # Find the end using same logic as extract
    block_start = toml_start + 8
    scan_pos = block_start
    in_triple_quote = False

    while scan_pos < len(synthesis_content):
        if synthesis_content[scan_pos : scan_pos + 3] == '"""':
            in_triple_quote = not in_triple_quote
            scan_pos += 3
            continue

        if (
            not in_triple_quote
            and synthesis_content[scan_pos : scan_pos + 4] == "\n```"
        ):
            after_fence = scan_pos + 4
            if (
                after_fence >= len(synthesis_content)
                or not synthesis_content[after_fence].isalpha()
            ):
                # Found the end
                toml_end = scan_pos
                # Reconstruct with new TOML
                before = synthesis_content[:toml_start]
                after = synthesis_content[toml_end + 4 :]  # Skip \n```
                return f"{before}```toml\n{new_toml}\n```{after}"

        scan_pos += 1

    return synthesis_content


def _summarize_validation(validation_content: str) -> tuple[Optional[dict], bool]:
    """Parse and display validation report summary.

    Returns:
        Tuple of (parsed data, has_issues) where has_issues is True if any
        recommendations need revision or were rejected.
    """
    data = _parse_validation_toml(validation_content)

    if data is None:
        click.echo(
            "  (Validation TOML parse error - see validation-report.md for details)"
        )
        return None, False

    # Display summary
    validation = data.get("validation", {})
    click.echo()
    click.echo("Validation Summary:")
    click.echo(f"  Total reviewed: {validation.get('total_reviewed', '?')}")
    click.echo(f"  Passed: {validation.get('passed', '?')}")
    click.echo(f"  Needs revision: {validation.get('needs_revision', '?')}")
    click.echo(f"  Rejected: {validation.get('rejected', '?')}")

    # Show issues for non-passing recommendations
    reviews = data.get("review", [])
    issues_found = [r for r in reviews if r.get("verdict") != "PASS"]

    if issues_found:
        click.echo()
        click.echo("Issues found:")
        for review in issues_found:
            verdict = review.get("verdict", "?")
            title = review.get("title", "?")
            click.echo(f"  [{verdict}] {title}")
            for issue in review.get("issues", []):
                click.echo(f"    - {issue}")

    has_issues = bool(issues_found)
    return data, has_issues


def _run_global_synthesis(ctx, cfg: Config, analysis_dir: Path):
    """Run global synthesis on existing per-project analyses."""
    import asyncio
    from .analyzer.session_analyzer import SessionAnalyzer
    from .analyzer.claude_client import AnalyzerClaudeClient

    # Count analysis files (excluding synthesis and validation outputs)
    analysis_files = [
        f
        for f in analysis_dir.glob("*.md")
        if f.name.lower() not in ("global-synthesis.md", "validation-report.md")
    ]

    if not analysis_files:
        click.echo(f"No analysis files found in {analysis_dir}")
        return

    click.echo("Starting global synthesis...")
    click.echo(f"Analysis directory: {analysis_dir}")
    click.echo(f"Project analyses found: {len(analysis_files)}")
    for f in sorted(analysis_files):
        click.echo(f"  - {f.name}")
    click.echo()

    async def run_synthesis():
        async with AnalyzerClaudeClient() as client:
            # Database not needed for synthesis, but required by SessionAnalyzer
            db = Database(cfg.db_path)
            with db:
                analyzer = SessionAnalyzer(
                    client=client,
                    db=db,
                    toml_dir=cfg.toml_dir,
                )

                click.echo("Running synthesis across all project analyses...")

                try:
                    result = await analyzer.synthesize_global(analysis_dir)

                    # Write initial synthesis
                    output_path = analysis_dir / "global-synthesis.md"
                    output_path.write_text(result)
                    click.echo(f"Written: {output_path}")

                    # Validation and fix loop
                    max_iterations = 2
                    for iteration in range(max_iterations):
                        # Run validation phase (quality gate)
                        click.echo()
                        click.echo(
                            f"Running quality validation (iteration {iteration + 1})..."
                        )
                        validation_result = (
                            await analyzer.validate_against_best_practices(result)
                        )

                        # Write validation report
                        validation_path = analysis_dir / "validation-report.md"
                        validation_path.write_text(validation_result)
                        click.echo(f"Written: {validation_path}")

                        # Parse and summarize validation results
                        validation_data, has_issues = _summarize_validation(
                            validation_result
                        )

                        if validation_data is None:
                            click.echo()
                            click.echo(
                                "Could not parse validation - skipping fix loop."
                            )
                            break

                        if not has_issues:
                            click.echo()
                            click.echo("All recommendations passed validation.")
                            break

                        if iteration == max_iterations - 1:
                            click.echo()
                            click.echo(
                                "Max iterations reached. Some issues remain unfixed."
                            )
                            break

                        # Extract issues and run fix
                        click.echo()
                        click.echo("Running recommendation fixes...")

                        original_toml = _extract_toml_from_synthesis(result)
                        if not original_toml:
                            click.echo("  (Could not extract TOML from synthesis)")
                            break

                        issues_text = _format_validation_issues(validation_data)
                        fixed_toml = await analyzer.fix_recommendations(
                            original_toml, issues_text
                        )

                        # Extract just the TOML from the fix response
                        fixed_toml_start = fixed_toml.find("```toml\n")
                        fixed_toml_end = fixed_toml.rfind("\n```")
                        if fixed_toml_start != -1 and fixed_toml_end > fixed_toml_start:
                            fixed_toml_content = fixed_toml[
                                fixed_toml_start + 8 : fixed_toml_end
                            ]
                        else:
                            fixed_toml_content = fixed_toml

                        # Replace TOML in synthesis
                        result = _replace_toml_in_synthesis(result, fixed_toml_content)
                        output_path.write_text(result)
                        click.echo(f"Updated: {output_path}")

                except ValueError as e:
                    click.echo(f"Error: {e}")

    try:
        asyncio.run(run_synthesis())
        click.echo()
        click.echo("Synthesis complete.")
    except ValueError as e:
        if "ANTHROPIC_API_KEY" in str(e):
            click.echo(f"\nError: {e}")
        else:
            raise


def _run_recommendations(ctx, cfg: Config, synthesis_path: Path):
    """Generate actionable recommendations from a synthesis file."""
    from .analyzer.recommendations import (
        parse_recommendations_from_synthesis,
        RecommendationGenerator,
    )

    click.echo("Generating recommendations...")
    click.echo(f"Synthesis file: {synthesis_path}")

    try:
        recommendations = parse_recommendations_from_synthesis(synthesis_path)
    except ValueError as e:
        click.echo(f"Error parsing synthesis: {e}")
        return

    if not recommendations:
        click.echo("No recommendations found in synthesis file.")
        click.echo(
            "Ensure the synthesis was generated with the updated prompt "
            "that includes structured TOML output."
        )
        return

    click.echo(f"Found {len(recommendations)} recommendations:")
    for rec in recommendations:
        click.echo(f"  - [{rec.category.value}] {rec.title}")

    # Output directory is in same location as synthesis file
    output_dir = synthesis_path.parent / "recommendations"
    generator = RecommendationGenerator(output_dir)

    click.echo()
    click.echo(f"Generating output files to: {output_dir}")

    generated = generator.generate_all(recommendations)

    click.echo()
    click.echo("Generated files:")
    for path in generated:
        click.echo(f"  - {path.name}")

    click.echo()
    click.echo(f"Done. {len(generated)} files generated.")


if __name__ == "__main__":
    main()
